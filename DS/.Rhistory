A
# Variables and Classes
a <- 3.0
b <- 4.5
class(a)
class(b) == 'character'
a^2 + 1/b
sqrt(a*b)
log2(a)
# Matrix algebra
A = matrix(c(1:8, 10), nrow=3, byrow=TRUE)
B = matrix(c(1:9), nrow=3)
y = matrix(c(1:3))
a * A
A %*% B
invA = solve(A)
A %*%invA
t(B)
B[1,] = c(1,1,1)
ols = function(A, y) solve(t(A)%*%A)%*%t(A)%*%y
ols(A, y)
# Indexing
# A B y (anzeigen)
A[3,2] * B[2,1]
A[1,] * B[,3]
y[y>1]
A[,2][A[,1] >= 4]
# A[4,]
# Custom function
standardize = function(x) {
if (is.numeric(x)){
mu = mean(x)
std = sd(x)
return((x - mu) / std)
}
else{
return(x)
}
}
a = c(-100, -25, -10, 0, 10, 25, 100)
standardize(a)
# Using inbuilt-functions
dnorm(x = c(1,2,3,6))
x = seq(-2,2, by=0.2)
nvValues = dnorm(x, mean = 0, sd = 1)
plot(x = x, y = nvValues, type='l')
ols(A, y)
A[,2][A[,1] >= 4]
x<-10
y <-10:15
z <- c('Hi', 'everyone')
l <- list(x,y,z)
l
l[1]
l[[1]]
class(l[[1]])
l
# All columns in the data.frame have to have the same length
# But they can have different classes
x <- 1:5
y <- seq(from = 1, to = 10, by = 2)
z <- c("a", "b", "c", "d", "e")
# Create a data.frame
df <- data.frame(x, y, z)
df
df <- data.frame("column1" = x, "column2" = y, z)
df
# We can reassign names, just like we reassigned dimensions
colnames(df) <- c("variable1", "variable2", "variable3")
rownames(df) <- c("obs1", "obs2", "obs3", "obs4", "obs5")
df
# Indexing data frames
# By position
df[1:2,]
df[,2:3]
df[,2]
# By name...
df[c("obs4", "obs5"), c("variable1", "variable2")]
# ...with a shortcut $ for selecting one column by name
df$variable2
df["variable2"]
# Calculating the mean of variable 2
mean(df$variable2)
# All columns in the data.frame have to have the same length
# But they can have different classes
x <- 1:5
y <- seq(from = 1, to = 10, by = 2)
z <- c("a", "b", "c", "d", "e")
# Create a data.frame
df <- data.frame(x, y, z)
df
df
df <- data.frame("column1" = x, "column2" = y, z)
df
# We can reassign names, just like we reassigned dimensions
colnames(df) <- c("variable1", "variable2", "variable3")
rownames(df) <- c("obs1", "obs2", "obs3", "obs4", "obs5")
df[1:2]
df
df[1:3]
df[1:1]
df[1:2]
df[,2:3]
df[:-1,2:3]
df[:2,2:3]
df[,2:3]
df[2:3]
df[,2]
df$variable2
df[2,]
df[2:3,2:3]
df[:3,2:3]
df[3:,2:3]
summary(loans)
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
summary(loans)
class(loans$YOB)
print(class(loans[col]))
colnames(loans)
for(col in colnames(loans)){
print(class(loans[col]))
}
loans[YOB]
loans["YOB"]
class(loans["YOB"])
class(loans$YOB)
class(loans$BAD)
?glm()
lr <- glm(formula = BAD ~.-BAD, data=loans)
lr <- glm(formula = BAD ~., data=loans)
?glm()
lr <- glm(formula = BAD ~ ., data=loans)
lr <- glm(formula = BAD ~ ., data=loans, family=binomial())
lr
summary(lr)
# Get the significant columns
lr$coefficients
# Get the significant columns
lr$coefficients[Pvalue]
# Get the significant columns
lr$coefficients[]
# Get the significant columns
lr$pvale
# Get the significant columns
lr$pvalue
# Get the significant columns
coef(summary(lr))[,4]
# Get the significant columns
coef(summary(lr))
# Get the significant columns
coef(summary(lr))[,4]
class(coef(summary(lr))[,4])
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# Linear regression
lr <- lm(dINC_A ~.-BAD, data=loans)
prepData <- model.matrix(dINC_A ~ .-BAD, data=loans)
head(prepData)
summary(lr)
coef(summary(lr))
# Get the significant columns
summary(lr)$coeff[,4] < 0.05
# Get the significant columns
summary(lr)$coeff[,4] < 0.05
# Get the significant columns
class(summary(lr)$coeff[,4] < 0.05)
loans[selector]
# Get the significant columns
selector <- summary(lr)$coeff[,4] < 0.05
loans[selector]
selector
selector[True]
selector[TRUE]
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
selector
selector$YOB
type(selector)
class(selector)
selector[0]
which(selector, arr.ind = TRUE)
summary(lr)
which(selector, arr.ind = TRUE)
pred.lr <- predict(lr, newdata = loans)
summary(pred.lr)
?predict
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# Linear regression
lr <- lm(dINC_A ~.-BAD, data=loans)
prepData <- model.matrix(dINC_A ~ .-BAD, data=loans)
head(prepData)
summary(lr)
coef(summary(lr))
pred.lr <- predict(lr, newdata=loans)
summary(pred.lr)
library('Caret')
install.packages("caret")
library('caret')
library('caret')
conf_Mat <- table(loans$BAD, pred.lr)
conf_Mat
conf_Mat
accuracy <- sum(diag(conf_Mat))/sum(conf_Mat)
accuracy
conf_Mat <- table(loans$BAD, pred.lr)
accuracy <- sum(diag(conf_Mat))/sum(conf_Mat)
accuracy
conf_Mat
pred.lr
summary(pred.lr)
# General logistic regression
lr <- glm(formula = BAD ~ .-BAD, data=loans, family=binomial())
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans)
summary(pred.lr)
summary(pred.lr)
conf_Mat <- table(loans$BAD, pred.lr)
accuracy <- sum(diag(conf_Mat))/sum(conf_Mat)
accuracy
conf_Mat
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(), method="class")
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans)
summary(pred.lr)
summary(pred.lr)
conf_Mat <- table(loans$BAD, pred.lr)
accuracy <- sum(diag(conf_Mat))/sum(conf_Mat)
accuracy
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'), method="class")
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'))
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
classification_error <- mean(pred.lr != loans$BAD)
print(paste('Accuracy'), 1-classification_error)
print(paste('Accuracy', 1-classification_error))
loans$BAd
loans$Bad
loans$BAD
as.integer(loans$BAD)
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr != y)
print(paste('Accuracy', 1-classification_error))
y
pred.lr
pred.lr <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr != y)
print(paste('Accuracy', 1-classification_error))
y
lr
pred.lr
summary(pred.lr)
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'))
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
which(selector, arr.ind = TRUE)
summary(pred.lr)
pred.lr <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr != y)
print(paste('Accuracy', 1-classification_error))
abs(y-pred.lr)
sum(abs(y-pred.lr))
sum(abs(y-pred.lr))/size(y)
sum(abs(y-pred.lr))/length(y)
1-sum(abs(y-pred.lr))/length(y)
print(paste('Accuracy', 1-classification_error))
# Brier score
sum((y-pred.lr[,2])^2) / length(y)
# Brier score
pred.lr
classification_error <- mean(pred.lr.logit != y)
pred.lr.logit <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr.logit != y)
print(paste('Accuracy', 1-classification_error))
# Brier score
pred.lr
sum((y-pred.lr[,2])^2) / length(y)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='probability')
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='prob')
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
summary(pred.lr)
pred.lr.logit <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr.logit != y)
print(paste('Accuracy', 1-classification_error))
# Brier score
pred.lr
sum((y-pred.lr[,2])^2) / length(y)
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# Linear regression
lr <- lm(dINC_A ~.-BAD, data=loans)
prepData <- model.matrix(dINC_A ~ .-BAD, data=loans)
head(prepData)
summary(lr)
coef(summary(lr))
pred.lr <- predict(lr, newdata=loans)
summary(pred.lr)
summary(loans$dINC_A)
MAE <- mean(abs(loans$dINC_A - pred.lr))
MAE
#### Clustering
idx_numeric <- sapply(loans, is.numeric)
kmeans <- kmeans(x=loans[idx_numeric], centers=5, iter.max = 50, nstart=25)
k_settings  <- c(seq(1,15))
obj_values  <- vector(length = 15)
kmeans['tot.withinss']
for(i in k_settings){
cluster_solution <- kmeans(x=loans[idx_numeric], centers=i)
obj_values[i] <- cluster_solution['tot.withinss']
}
## alternative
my.kMeans <- function(k){
clu.sol <- kmeans(loans[idx_numeric], centers=k)
return(clu.sol$tot.withinss)
}
obj_values <- sapply(k_settings, my.kMeans)
plot(x=k_settings, y=obj_values, type='l')
str(kmeans)
system.time({
for(i in k_settings){
cluster_solution <- kmeans(x=loans[idx_numeric], centers=i)
obj_values[i] <- cluster_solution['tot.withinss']
}
})
system.time({
obj_values <- sapply(k_settings, my.kMeans)
})
## Train a tree model
library("rpart")
library("rpart.plot")
dt <- rpart(BAD ~ ., data = loans, method = "class")
summary(dt)
# Calculate performance according to brier score
pred.dt <- predict(dt, newdata= loans, type="prob")
y <- as.numeric(loans$BAD) -1
sum((y-pred.dt[,2])^2) / length(y)
prp(dt)
prp(dt, extra = 104, border.col = 0, box.palette = "auto")
pred.dt[,2]
pred.dt[,1]
pred.dt
pred.lr
sum((y-pred.lr)^2) / length(y)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='prob')
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='reponse')
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'))
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
summary(pred.lr)
pred.lr.logit <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr.logit != y)
print(paste('Accuracy', 1-classification_error))
# Brier score
pred.lr
sum((y-pred.lr)^2) / length(y)
library('glmnet')
install.packages("glmnet")
# standardize data
numeric_idx <- sapply(loans, is.numeric)
standardize(c(0,1,2,3))
loans[numeric_idx] <- sapply(loans[numeric_idx], standardize)
loans
loans[numeric_idx]
loans[numeric_idx && !loans$dINC_A]
loans[numeric_idx && !loans$dINC_A]
t
loans[(numeric_idx) && !(loans$dINC_A)]
loans[loans$dINC_A]
t <- loans[numeric_idx, names(loans[numeric_idx]!= "dINC_A")]
t
t <- loans[numeric_idx]
t
t[, !(names(t) %in% c('dINC_A'))]
t <- t[, !(names(t) %in% c('dINC_A'))]
target_space <- loans$dINC_A <- loans[numeric_idx]
input_space <- loans[numeric_idx && !(names(loans[numeric_idx]) %in% c('dINC_A'))]
input_space
input_space
target_space
target_space <- loans$dINC_A
input_space <- loans[numeric_idx && !(names(loans[numeric_idx]) %in% c('dINC_A'))]
input_space
target_space
target_space
loans
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'))
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
summary(pred.lr)
pred.lr.logit <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr.logit != y)
print(paste('Accuracy', 1-classification_error))
# Brier score
sum((y-pred.lr)^2) / length(y)
# glmnet library for lasso-regularized logistic regression
library('glmnet')
# standardize data
numeric_idx <- sapply(loans, is.numeric)
loans[numeric_idx] <- sapply(loans[numeric_idx], standardize)
target_space <- loans$dINC_A
input_space <- loans[numeric_idx && !(names(loans[numeric_idx]) %in% c('dINC_A'))]
input_space
target_space
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans = GetLoanDataset(file="Loan_Data.csv")
# General logistic regression
lr <- glm(formula = BAD ~ ., data=loans, family=binomial(link='logit'))
summary(lr)
# Get the significant columns
selector <- summary(lr)$coeff[-1,4] < 0.05
which(selector, arr.ind = TRUE)
# Predict on loans (tasks requires it)
pred.lr <- predict(lr, newdata = loans, type='response')
summary(pred.lr)
pred.lr.logit <- ifelse(pred.lr > 0.5, 1,0) #map logit to classes
y <- as.integer(loans$BAD) -1
classification_error <- mean(pred.lr.logit != y)
print(paste('Accuracy', 1-classification_error))
# Brier score
sum((y-pred.lr)^2) / length(y)
# glmnet library for lasso-regularized logistic regression
library('glmnet')
# standardize data
numeric_idx <- sapply(loans, is.numeric)
loans[numeric_idx] <- sapply(loans[numeric_idx], standardize)
#target_space <- loans$dINC_A
#input_space <- loans[numeric_idx && !(names(loans[numeric_idx]) %in% c('dINC_A'))]
#input_space
#target_space
loans
loans$dINC_A
target_space <- loans$dINC_A
target_space <- loans$dINC_A
target_space
loans[numeric_idx]
loans[numeric_idx && !(names(loans[numeric_idx]) %in% c('dINC_A'))]
loans[numeric_idx || !(names(loans[numeric_idx]) %in% c('dINC_A'))]
loans[numeric_idx & !(names(loans[numeric_idx]) %in% c('dINC_A'))]
loans[(numeric_idx) & (!(names(loans[numeric_idx]) %in% c('dINC_A')))]
loans[(numeric_idx) && (!(names(loans[numeric_idx]) %in% c('dINC_A')))]
loans[(numeric_idx) & (!(names(loans[numeric_idx]) %in% c('dINC_A')))]
input_space <- loans[numeric_idx & !(names(loans[numeric_idx]) %in% c('dINC_A'))]
?glmnet
glm(x=input_space, y=target_space, family='gaussian')
glmnet(x=input_space, y=target_space, family='gaussian')
glmnet(x=input_space, y=target_space, family='gaussian')
# glmnet library for lasso-regularized logistic regression
library('glmnet')
glmnet(x=input_space, y=target_space, family='gaussian')
