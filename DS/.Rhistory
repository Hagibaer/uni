# Variables and Classes
a <- 3.0
b <- 4.5
class(a)
class(b) == 'character'
a^2 + 1/b
sqrt(a*b)
# Matrix algebra
A = matrix(c(1,4,7,2,5,8,3,6,10), nrow=3)
B = matrix(c(1:9), nrow=3)
y = matrix(c(1:3))
a * A
A %*% B
invA = solve(A)
A %*%invA
t(B)
B[1,] = c(1,1,1)
ols = function(A, y) solve(t(A)%*%A)%*%t(A)%*%y
ols(A, y)
# Indexing
# A B y (anzeigen)
A[3,2] * B[2,1]
A[1,] * B[,3]
y[y>1]
A[,2][A[,1] >= 4]
# Custom function
standardize = function(x) {
if (is.numeric(x)){
mu = mean(x)
std = sd(x)
return((x - mu) / std)
}
else{
return(x)
}
}
a = c(-100, -25, -10, 0, 10, 25, 100)
standardize(a)
# Using inbuilt-functions
dnorm(x = c(1,2,3,6))
x = seq(-2,2, by=0.2)
nvValues = dnorm(x, mean = 0, sd = 1)
plot(x = x, y = nvValues, type='l')
B <- matrix(c(1,1,0,0,1,1,0,0,0,0,1,1,0,0,1,1), ncol=4)
B
eigen(B)
A <- matrix(c(1, sqrt(2), sqrt(2), 0),ncol = 2)
eigen(A)
# setup
setwd("C:/Users/Hagen/uni/DS")
X_train = read.csv(file="Submission_1/data/X_train", header=TRUE, sep=",")
# setup
setwd("C:/Users/Hagen/uni/DS")
X_train = read.csv(file="Submission_1/data/X_train", header=TRUE, sep=",")
cwd()
wd()
# setup
setwd("C:/Users/Hagen/uni/DS")
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=TRUE, sep=",")
X_train.head()
head(X_train)
X_train$X
X_test$X
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train$X0
names(y_train)
y_train <- y_train[ , !(names(y_train) %in% drops)]
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
drops <- c("x0")
y_train <- y_train[ , !(names(y_train) %in% drops)]
y_train
y_train$X0
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
type(y_train)
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
class(y_train)
y_train <- y_train$X1
y_train
class(y_train)
X_train[1:]
X_train[,1:]
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=TRUE, sep=",")
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train$x0 <- NULL
y_train
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train$x0 <- NULL
y_train
ncol(y_train)
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train$X1
ncol(y_train))
ncol(y_train)
y_train
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train[, 1:2]
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train[, 1:3]
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train[, 0:1]
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=TRUE, sep=",")
y_train[, 0:1]
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train[, 1:2]
y_train[, 1:2]
y_train
y_train[, 1:1]
# Get rid of first column (= id from the pandas data_frame, that got saved into the csv)
y_train <- y_train[, 2:2]
y_train[, 2:2]
y_train
class(y_train)
X_train[, 1:ncol(X_train)]
X_train <- X_train[, 2:ncol(X_train)]
X_train
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_train
X_train <- X_train[, 2:ncol(X_train)]
X_train
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
install.packages('glmnet')
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
# Load prepared data
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=TRUE, sep=",")
View(y_train)
View(X_test)
# Load prepared data
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=TRUE, sep=",")
X_train
View(y_train)
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- model.matrix(X_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- data.matrix(y_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
rlm_predict
View(rlm_predict)
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict
View(rlm_predict)
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=","
)
View(X_test)
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- data.matrix(y_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- data.matrix(y_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# setup
setwd("C:/Users/Hagen/uni/DS")
# Load prepared data
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- data.matrix(y_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict
View(rlm_predict)
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
rlm <-glmnet(x=X_train, y=as.factor(y_train), family='binomial', standardize=TRUE, alpha=1)
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- data.matrix(y_train)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#Set-up
setwd("C:/Users/Hagen/uni/DS")
source(file = "Rintro_HelperFunctions.R")
loans <- GetLoanDataset(file="Loan_Data.csv")
# logistic regression
lr <- glm(formula = BAD ~ . -BAD, data=loans, family=binomial(link='logit'))
# lasso-regularized
library('glmnet')
target_space <- loans$BAD
target_space
class(target_space)
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- as.factor(y_train)
class(y_train)
y_train$V1
as.factor(y_train$V1)
# Load prepared data
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- as.factor(y_train$V1)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response")
summary(rlm_predict)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response", s=0.01)
summary(rlm_predict)
rlm_predict
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict
rlm_predict2
rlm_predict_2 <- predict(rlm, newx=X_train ,type = "response", s=0.01)
summary(rlm_predict)
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict2 <- ifelse(rlm_predict2 > 0.5, 1, 0)
rlm_predict2
rlm_predict_2 <- predict(rlm, newx=X_train ,type = "response", s=0.01)
summary(rlm_predict)
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
rlm_predict2 <- ifelse(rlm_predict2 > 0.5, 1, 0)
rlm_predict2 <- ifelse(rlm_predict_2 > 0.5, 1, 0)
rlm_predict2
y_train - rlm_predict2
as.numeric(y_train) - rlm_predict2
y_train - rlm_predict2
rlm_predict2
class(rlm_predict2)
View(rlm_predict_2)
View(rlm_predict2)
View(y)
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
y_train -rlm_predict2
sum(y_train -rlm_predict2)
sum(abs(y_train -rlm_predict2)
sum(abs(y_train -rlm_predict2)
)
sum(abs(y_train -rlm_predict2))
(100000 - 37857) / 100000
class(rlm_predict2)
CSV.write('predicted_labels.csv', rlm_predict2, append = FALSE)
write.csv(rlm_predict2, file = "predictions.csv")
# Create a dataframe with two columns: order_item_id = 100001 - 150000
order_item_id = seq(from=100001, to=150000, by = 1)
order_item_id
tail(order_item_id)
return = rlm_predict2
return
df = df(order_item_id, return, row.names = ['order_item_id', 'return'])
df = df(order_item_id, return, row.names = ('order_item_id', 'return'))
df = df(order_item_id, return, row.names = c('order_item_id', 'return'))
df = df(order_item_id, return)
df = data.frame(order_item_id, return, row.names = c('order_item_id', 'return'))
df = data.frame(order_item_id, return, row.names = ['order_item_id', 'return'])
df = data.frame(order_item_id, return)
df
tail(df)
colnames(df) <- c('order_item_id', 'return')
df
write.csv(df, '589187_mohr.csv')
?write.csv
write.csv(df, '589187_mohr.csv', row.names = FALSE)
# setup
setwd("C:/Users/Hagen/uni/DS")
# Load prepared data
X_train = read.csv(file="Submission_1/data/X_train.csv", header=TRUE, sep=",")
X_test = read.csv(file="Submission_1/data/X_test.csv", header=TRUE, sep=",")
y_train = read.csv(file="Submission_1/data/y_train.csv", header=FALSE, sep=",")
# Best model from the set (Logistic_Regression, Decision_Tree, Random_Forest, Bayes) was LR (tested in Python skript)
X_train <- data.matrix(X_train)
X_test <- data.matrix(X_test)
y_train <- as.factor(y_train$V1)
# Train model
library('glmnet')
rlm <-glmnet(x=X_train, y=y_train, family='binomial', standardize=TRUE, alpha=1)
#predict
rlm_predict <- predict(rlm, newx=X_test ,type = "response", s=0.01)
rlm_predict <- ifelse(rlm_predict > 0.5, 1, 0)
# Create a dataframe with two columns: order_item_id = 100001 - 150000 and return = prediction
order_item_id = seq(from=100001, to=150000, by = 1)
return = rlm_predict
return <- sapply(return, function(x) paste0("'", x)) # to outsmart excel
df = data.frame(order_item_id, return)
colnames(df) <- c('order_item_id', 'return')
write.csv(df, '589187_mohr.csv', row.names = FALSE)
