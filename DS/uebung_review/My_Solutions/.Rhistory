source(file = "./helper/Rintro_HelperFunctions.R")
source(file = "/helper/Rintro_HelperFunctions.R")
gwd()
pwd()
wd()
getwd()
setwd("C:/Users/hagen/uni/DS/uebung_review/My_Solutions")
source(file = "../helper/Rintro_HelperFunctions.R")
# 2 load cleaned data
loans <- GetLoanDataset()
# 2 load cleaned data
loans <- GetLoanDataset()
#1 Load helperfile
source(file = "../helper/Rintro_HelperFunctions.R")
# 2 load cleaned data
loans <- GetLoanDataset()
# get only numeric columns
numeric_idx <- sapply(loans, is.numeric)
numeric_idx
loans_numeric <- loans[numeric_idx]
loans_numeric
loans_numeric
loans[,numeric_idx]
loans_numeric <- loans[,numeric_idx]
?kmeans
cluster.object <- kmeans(loans_numeric, 5, iter.max=50, nstart=25)
summary(cluster.object)
structure(cluster.object)
# structure(cluster.object)
cluster.object$cluster
# structure(cluster.object)
clusters <- cluster.object$cluster
obj.values <- vec(k-range)
obj.values <- vector(k-range)
obj.values <- vector(mode = "numeric", length = length(k-range))
# Empirically test for 'good' k
k-range <- 1:15
obj.values <- vector(mode = "numeric", length = length(k_range))
# Empirically test for 'good' k
k_range <- 1:15
# Empirically test for 'good' k
k_range <- 1:15
obj.values <- vector(mode = "numeric", length = length(k_range))
obj.values
cluster.models <- vector(mode="list", length = length(k_range))
for(i in 1:length(k_range)){
cluster.solution <- kmeans(loans_numeric, i, iter.max=50, nstart=25)
obj.values[i] <- cluster.solution$tot.withinss
cluster.models[[i]] <- cluster.solution # two brackets because cluster.solution is list in list, stupid R here we go
}
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="darkgreen") + guides(color=FALSE)
if(!require("ggplot2")) install.packages("ggplot2")
library("ggplot2")
par(mar=c(2,2,2,2)) # some settings for the size
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="darkgreen") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="darkgreen")
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="darkgreen") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="green") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="brown") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="green") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", color="brown") + guides(color=FALSE)
?qplot
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", colour="brown") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", colour="green") + guides(color=FALSE)
?qplot
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", colour="cyl") + guides(color=FALSE)
qplot(x = k_range, y=obj.values, geom = c("line", "point"), xlab = "Number of centers", ylab="sum of squares",
main="elbow curve for k selections", colour="green") + guides(color=FALSE)
rt") install.packages("rpart"))
library("rpart")
######### Decision Trees #######
if(!require("rpart")) install.packages("rpart"))
######### Decision Trees #######
if(!require("rpart")) install.packages("rpart")
library("rpart")
decision_tree <- rpart(data = loans)
?rpart
decision_tree <- rpart(formula = BAD ~ . ,data = loans)
prediction.dt <- predict(decision_tree, newdata = loans, type = 'prob')[,2] # in sample
y
# get performance baseline
y <- as.numeric(loans$BAD)
y
# get performance baseline
y <- as.numeric(loans$BAD) - 1 # -1  because R
brier.base <- sum((y-1)^2)/length(y)
brier.dt <- sum((y-predction.dt)^2)/length(y)
decision_tree <- rpart(formula = BAD ~ . ,data = loans)
prediction.dt <- predict(decision_tree, newdata = loans, type = 'prob')[,2] # in sample
brier.dt <- sum((y-predction.dt)^2)/length(y)
brier.dt <- sum((y-prediction.dt)^2)/length(y)
brier.base
brier.dt
?rpart.plot()
rpart.plot(decision_tree)
if(!require("rpart.plot")) install.packages("rpart.plot")
library("rpart.plot")
rpart.plot(decision_tree)
prp(decision_tree)
prp(decision_tree, extra = 104, border.col = 0, box.palette = "auto")
decision_tree <- rpart(formula = BAD ~ . ,data = loans, method = "class")
decision_tree <- rpart(formula = BAD ~ . ,data = loans, method = "class")
prediction.dt <- predict(decision_tree, newdata = loans, type = 'prob')[,2] # in sample
R
brier.base <- sum((y-1)^2)/length(y)
brier.dt <- sum((y-prediction.dt)^2)/length(y)
brier.base
brier.dt
if(!require("rpart.plot")) install.packages("rpart.plot")
library("rpart.plot")
prp(decision_tree, extra = 104, border.col =
# get performance baseline
y <- as.numeric(loans$BAD) - 1 # -1  because R
# get performance baseline
y <- as.numeric(loans$BAD) - 1 # -1  because R
brier.base <- sum((y-1)^2)/length(y)
brier.dt <- sum((y-prediction.dt)^2)/length(y)
brier.base
brier.dt
if(!require("rpart.plot")) install.packages("rpart.plot")
library("rpart.plot")
prp(decision_tree, extra = 104, border.col = 0, box.palette = "auto")
dt.prunedLess <-rpart(formula = BAD ~ ., data = loans, method = "class", cp=0.005, minbucket=4)
dt.prunedMore <-rpart(formula = BAD ~ ., data = loans, method = "class", cp=0.02, minbucket=8)
dt.full <- rpart(formula = BAD ~ ., data=loans, method = "class", cp=0.005, minsplit = 3)
prp(dt.prunedLess)
prp(dt.prunedMore)
prediction.dt.full <- predict(dt.full, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.less <- predict(dt.prunedLess, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.mor
prediction.dt.full <- predict(dt.full, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.less <- predict(dt.prunedLess, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.more <- predict(dt.prunedMore, newdata = loans, type = 'prob')[,2] # in sample
# get predictions
prediction.dt.full <- predict(dt.full, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.less <- predict(dt.prunedLess, newdata = loans, type = 'prob')[,2] # in sample
prediction.dt.more <- predict(dt.prunedMore, newdata = loans, type = 'prob')[,2] # in sample
# Get brier scores
brier.full <- sum((y-prediction.dt.full)^2)/length(y)
brier.less <- sum((y-prediction.dt.less)^2)/length(y)
brier.more <- sum((y-prediction.dt.more)^2)/length(y)
brier.base
brier.full
brier.less
brier.more
# Regularization
loans <- GetLoanDataset()
?glm
lr <- glm(formula = BAD ~ ., family = binomial(link = "logit"), data=loans)
str(lr)
lr$coefficients
significant <- vector()
exp(coef(lr))
summary(lr)
# summary(lr)
pred.lr <- predict(object = lr, newdata = loans, type = "response")
pred.lr <- predict(object = lr, newdata = loans, type = "response")
y <- loans$BAD -1
class.lr <- ifelse(pred.lr > 0.5, "bad", "good")
accuracy <- vector()
accuracy["lr"] <- sum(class.lr == loans$BAD / length(class.lr))
accuracy["lr"] <- sum(class.lr == loans$BAD) / length(class.lr))
accuracy["lr"] <- sum(class.lr == loans$BAD) / length(class.lr)
accuracy
acc <- sum(predClass == class) / length(class)
Accuracy <- function(prediction, class, threshold=0.5){
predClass <- ifelse(prediction < threshold, levels(class)[2], levels(class)[1])
acc <- sum(predClass == class) / length(class)
return(acc)
}
# Get a benchmark
baseline_probability <- sum(loans$BAD == "bad" / nrow(loans))
# Get a benchmark
baseline_probability <- sum(loans$BAD == "bad") / nrow(loans)
baseline_probability
?rep
rep(1, 3)
class.benchmark <- rep(baseline_probability, nrows(loans))
class.benchmark <- rep(baseline_probability, nrow(loans))
accuracy["benchmark"] <- Accuracy(prediction = class.benchmark, loans$BAD, threshold=0.5)
accuracy
class.random <- sample(c(0,1), size= nrow(loans), replace = TRUE, prob = c(1-baseline_probability, baseline_probability))
accuracy["random"] <- Accuracy(prediction = class.random, loans$BAD, threshold = 0.5)
accuracy
class.lr <- ifelse(pred.lr > 0.5, 1, 0)
brier.lr <- sum((y - class.lr)^2) / length(y)
brier.lr
y
y <- loans$BAD - 1
y <- as.numeric(loans$BAD) - 1
y
brier.lr <- sum((y - class.lr)^2) / length(y)
brier.lr
brier.base <- sum((y - 1)^2) / length(y)
brier.base
brier.base <- sum((y - 0)^2) / length(y)
brier.base
if(!require("glmnet")) install.packages("glmnet")
library("glmnet")
?glmnet
?model.matrix
x <- model.matrix(formula=BAD ~ . -1 , data=loans)
x <- model.matrix(object=BAD ~ . -1 , data=loans)
x
y <- loans$BAD
y
glm_lr <- glmnet(x = x, y = y, family = "binomial", alpha=1, nlambda = 100)
summary(glm_lr)
str(glm_lr)
glm_lr
plot(glm_lr, xvar="lambda")
plot(lasso, xvar="dev")
plot(glm_lr, xvar="dev")
coef(glm_net, 0.01)
coef(glm_lr, 0.01)
plot(y = glm_lr$dev.ratio, x = glm_lr$lambda)
pred.lasso <-predict(glm_lr, newx = x, s  = 0.01, type="response")
pred.lasso
accuracy.lasso <- Accuracy(pred.lasso, class=loans$BAD)
accuracy.lasso
setwd("C:/Users/hagen/uni/DS/uebung_review/My_Solutions")
#1 Load helperfile
source(file = "../helper/Rintro_HelperFunctions.R")
loans <- GetLoanDataset()
x <- model.matrix(object =  BAD . ~, data=loans)
x <- model.matrix(object =  BAD ~ ., data=loans)
x
y <- loans$BAD
y
lr <- glm(formula = BAD ~ ., data=loans, family = binomal(link = "logit"))
lasso <- glmnet(x=x, y=y, family="binomial", alpha=1, nlambda=100)
dt <- rpart(formula = BAd ~ ., data = loans, cp="auto")
# Train three models
lr <- glm(formula = BAD ~ ., data=loans, family = binomial(link = "logit"))
lasso <- glmnet(x=x, y=y, family="binomial", alpha=1, nlambda=100)
dt <- rpart(formula = BAd ~ ., data = loans, cp="auto")
dt <- rpart(formula = BAD ~ ., data = loans, cp="auto")
dt <- rpart(formula = BAD ~ ., data = loans, cp="auto", method="class", minsplit=20)
yhat[["lr"]] <- predict(object = lr, newdata= loans, type = "response"))
yhat[["lr"]] <- predict(object = lr, newdata= loans, type = "response")
yhat <- list()
yhat[["lr"]] <- predict(object = lr, newdata= loans, type = "response")
predict(object=lasso, newdata=x, s = 0.001, type="response")
predict(object=lasso, newx=x, s = 0.001, type="response")
predict(object = lr, newdata= loans, type = "response")
yhat[["lasso"]] <- as.vector(predict(object=lasso, newx=x, s = 0.001, type="response"))
predict(object = dt, newdata = loans, type = "prob")
yhat[["dt"]] <- predict(object = dt, newdata = loans, type = "prob")[,2]
