{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read raw data\n",
    "df_train = pd.read_csv('../data/BADS_WS1718_known.csv', sep=',', na_values=['?', 'not_reported'])\n",
    "df_test = pd.read_csv('../data/BADS_WS1718_class.csv', sep=',', na_values=['?', 'not_reported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just to prove pythons superiority compared to R\n",
    "#for col in df_train.columns:\n",
    "#    print(df_train.groupby(col)['order_item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for col in df_test.columns:\n",
    "#    print(df_test.groupby(col)['order_item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Drop order_item_id -> no value\n",
    "df_train = df_train.drop(['order_item_id'], axis=1)\n",
    "df_test = df_test.drop(['order_item_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Convert date columns to datetime format:  order_date, delivery-date, user_reg_date, user_dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_columns = ['order_date', 'delivery_date', 'user_reg_date', 'user_dob']\n",
    "for date in date_columns:\n",
    "    df_train[date] = pd.to_datetime(df_train[date], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for date in date_columns:\n",
    "    df_test[date] = pd.to_datetime(df_test[date], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Calculate additional columns\n",
    "# 3.1 Length of customership  (LOC) (order_date - user_reg_date )\n",
    "df_train['LOC'] = (df_train.order_date - df_train.user_reg_date) / np.timedelta64(1, 'D')\n",
    "df_test['LOC'] = (df_test.order_date - df_test.user_reg_date) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.2 age of the customers df['age'] at the time of order (order_date - user_dob)\n",
    "df_train['age'] = np.round((df_train.order_date - df_train.user_dob) / np.timedelta64(1, 'Y'))\n",
    "df_test ['age'] = np.round((df_test.order_date - df_test.user_dob) / np.timedelta64(1, 'Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.3 delivery-time (DT) (order_date - delivery_date)\n",
    "df_train['DT'] = (df_train.delivery_date - df_train.order_date) / np.timedelta64(1, 'D')\n",
    "df_test['DT'] = (df_test.delivery_date - df_test.order_date) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.4 Number of past purchases (NPP)\n",
    "past_purchases = df_train.user_id.value_counts()\n",
    "df_train['npp'] = 0\n",
    "npp = []\n",
    "for elem in zip(df_train.user_id, df_train.npp):\n",
    "    npp.append(past_purchases[elem[0]])\n",
    "df_train.npp = npp\n",
    "\n",
    "past_purchases = df_test.user_id.value_counts()\n",
    "df_test['npp'] = 0\n",
    "npp = []\n",
    "for elem in zip(df_test.user_id, df_test.npp):\n",
    "    npp.append(past_purchases[elem[0]])\n",
    "df_test.npp = npp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3.5 Return rate of the customer\n",
    "# Update: NEVER use the target variable in feature engineering because it messes up the whole model\n",
    "# df_train.groupby('user_id')['return'].sum() --> I don't include it because it would not be independent from the npp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.6 split order_date, delivery_date into --> *_month, *year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['order_month'], df_train['order_year'] = df_train.order_date.dt.month, df_train.order_date.dt.year \n",
    "df_test['order_month'], df_test['order_year'] = df_test.order_date.dt.month, df_test.order_date.dt.year\n",
    "df_train['delivery_month'], df_train['delivery_year'] = df_train.delivery_date.dt.month, df_train.delivery_date.dt.year\n",
    "df_test['delivery_month'], df_test['delivery_year'] = df_test.delivery_date.dt.month, df_train.delivery_date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_date', 'delivery_date', 'item_id', 'item_size', 'item_color',\n",
       "       'brand_id', 'item_price', 'user_id', 'user_title', 'user_dob',\n",
       "       'user_state', 'user_reg_date', 'return', 'LOC', 'age', 'DT', 'npp',\n",
       "       'order_month', 'order_year', 'delivery_month', 'delivery_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop now obsolete columns\n",
    "df_train = df_train.drop(['order_date', 'delivery_date', 'user_dob', 'user_reg_date'], axis=1)\n",
    "df_test =  df_test.drop(['order_date', 'delivery_date', 'user_dob', 'user_reg_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # useful helper\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "#     print(#whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 5. Strategy for columns with a lot of different class labels\n",
    "# 5.1 item_id --> 3 Categories: popular item (bought >= 300 times), normal item (300 > x > 50), rare item (50 >= num_bought)\n",
    "def categorize_item_id(x, item_id_counts):\n",
    "    x = item_id_counts[x]\n",
    "    \n",
    "    if x > 300:\n",
    "        x = 'popular'\n",
    "    elif x > 50:\n",
    "        x = 'normal'\n",
    "    else:\n",
    "        x = 'rare'\n",
    "        \n",
    "    return x\n",
    "\n",
    "item_id_train_counts = df_train.item_id.value_counts()\n",
    "item_id_test_counts = df_test.item_id.value_counts()\n",
    "\n",
    "df_train['item_popularity'] = df_train.item_id.apply(lambda x: categorize_item_id(x, item_id_train_counts))\n",
    "df_test['item_popularity'] = df_test.item_id.apply(lambda x: categorize_item_id(x, item_id_test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.2 item_size --> join big letters and small letters into same group if the same (L + l); if count > 1000 --> keep, else --> other\n",
    "def categorize_item_size(x, item_size_count):\n",
    "        \n",
    "    count = item_size_count[x]\n",
    "    \n",
    "    if count < 1000:\n",
    "        x = 'other'\n",
    "    return x\n",
    "\n",
    "df_train.item_size = df_train.item_size.apply(lambda x: x.lower())\n",
    "df_test.item_size = df_test.item_size.apply(lambda x: x.lower())\n",
    "\n",
    "item_size_train_counts = df_train.item_size.value_counts()\n",
    "item_size_test_counts = df_test.item_size.value_counts()\n",
    "\n",
    "df_train.item_size = df_train.item_size.apply(lambda x: categorize_item_size(x, item_size_train_counts))\n",
    "df_test.item_size = df_test.item_size.apply(lambda x: categorize_item_size(x, item_size_test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.3 item_color --> if count > 2000 --> keep; else --> other\n",
    "def categorize_item_color(x, item_color_count):\n",
    "    \n",
    "    count = item_color_count[x]\n",
    "    \n",
    "    if count < 2000:\n",
    "       x = 'other'\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Convert NaNs to other\n",
    "df_train.item_color = df_train.item_color.fillna('other')\n",
    "df_test.item_color = df_test.item_color.fillna('other')\n",
    "\n",
    "item_color_train_counts = df_train.item_color.value_counts()\n",
    "item_color_test_counts = df_test.item_color.value_counts()\n",
    "\n",
    "df_train.item_color = df_train.item_color.apply(lambda x: categorize_item_color(x, item_color_train_counts))\n",
    "df_test.item_color = df_test.item_color.apply(lambda x: categorize_item_color(x, item_color_test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.4 brand_id --> if count > 2000 : popular; 2000 >= count > 500 : normal; Rest --> rare\n",
    "def categorize_brand_id(x, brand_id_count):\n",
    "    \n",
    "    count = brand_id_count[x]\n",
    "    \n",
    "    if count > 2000:\n",
    "        x = 'popular'\n",
    "    elif count > 500:\n",
    "        x = 'normal'\n",
    "    else:\n",
    "        x = 'rare'\n",
    "        \n",
    "    return x\n",
    "\n",
    "brand_id_train_counts = df_train.brand_id.value_counts()\n",
    "brand_id_test_counts = df_test.brand_id.value_counts()\n",
    "\n",
    "df_train['brand_popularity'] = df_train.brand_id.apply(lambda x: categorize_brand_id(x, brand_id_train_counts))\n",
    "df_test['brand_popularity'] = df_test.brand_id.apply(lambda x: categorize_brand_id(x, brand_id_test_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 delivery_month --> make nas to 'other'\n",
    "df_train.delivery_month = df_train.delivery_month.fillna('other')\n",
    "df_test.delivery_month = df_test.delivery_month.fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.6 delivery_year --> make nas to other\n",
    "df_train.delivery_year = df_train.delivery_year.fillna('other')\n",
    "df_test.delivery_year = df_test.delivery_year.fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.6 user_id --> nothing really that one could do here, since we already got number of purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again drop now unnecessary columns\n",
    "df_train = df_train.drop(['item_id', 'brand_id', 'user_id'], axis=1)\n",
    "df_test =  df_test.drop(['item_id', 'brand_id', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All columns are fine now in terms of data type and structure ###\n",
    "\n",
    "### Check columns for plausability ###\n",
    "\n",
    "# item_size                      | Train: Okay | Test: Okay\n",
    "# item_color                     | Train: Okay | Test: Okay\n",
    "# item_price                     --> Zero values, and two 999 values. Cant for sure be outliers --> stay; Rest okay\n",
    "# user_title                     | Train: Okay | Test: Okay\n",
    "# user_state                     | Train: Okay | Test: Okay\n",
    "# LOC                            | Train: Okay | Test: Okay\n",
    "# age                            | Train: needs work | Test: needs work --> Some are older than 100 and  smaller 15 !! --FIXED--\n",
    "# DT                             | Train: work | Test: work --> bunch of negative delivery times   --FIXED--\n",
    "# npp                            | Train: Okay | Test: Okay \n",
    "# order_month                    | Train: Okay | Test: Okay\n",
    "# order_year                     | Train: Okay | Test: Okay\n",
    "# delivery_month                 | Train: Okay | Test: Okay --> NaNs bei beiden --FIXED--\n",
    "# delivery_year                  | Train: Okay | Test: Okay --> NaNs bei beiden  und 1990 (unsinnig) --FIXED--\n",
    "# item_popularity                | Train: Okay | Test: Okay\n",
    "# brand_popularity               | Train: Okay | Test: Okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. fix age column: Every age > 80 == 80; and every age < 18 == 18\n",
    "def fix_age(x):\n",
    "    if x > 80:\n",
    "        x = 80\n",
    "    elif x < 18:\n",
    "        x = 18\n",
    "    return x\n",
    "\n",
    "# Fill NAs with median\n",
    "median_train_age = df_train.age.median()\n",
    "median_test_age = df_test.age.median()\n",
    "\n",
    "df_train.age = df_train.age.fillna(median_train_age)\n",
    "df_test.age = df_test.age.fillna(median_test_age)\n",
    "\n",
    "df_train.age = df_train.age.apply(lambda x: fix_age(x))\n",
    "df_test.age = df_test.age.apply(lambda x: fix_age(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.fix DT column: negative values come from 1990 delivery time --> impute to median delivery_time (mean from positive values)\n",
    "def fix_DT(x, mean_DT):\n",
    "    if x < 0:\n",
    "        x = mean_DT\n",
    "    return x\n",
    "\n",
    "median_train_DT = df_train.DT[df_train.DT >= 0].median()\n",
    "median_test_DT = df_test.DT[df_test.DT >= 0].median()\n",
    "\n",
    "#Fill NA DTs with median\n",
    "df_train.DT = df_train.DT.fillna(median_train_DT)\n",
    "df_test.DT = df_test.DT.fillna(median_test_DT)\n",
    "\n",
    "df_train.DT = df_train.DT.apply(lambda x: fix_DT(x, median_train_DT))\n",
    "df_test.DT = df_test.DT.apply(lambda x: fix_DT(x, median_test_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. fix delivery_year --> 1990 values will just be smoothed to 2012\n",
    "def fix_delivery_year(x):\n",
    "    if x == 'other':\n",
    "        return x\n",
    "    if x < 2012:\n",
    "        x = 2012\n",
    "    return x\n",
    "\n",
    "df_train.delivery_year = df_train.delivery_year.apply(lambda x: fix_delivery_year(x))\n",
    "df_test.delivery_year = df_test.delivery_year.apply(lambda x: fix_delivery_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data is correct and clean ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_size', 'item_color', 'item_price', 'user_title', 'user_state',\n",
       "       'return', 'LOC', 'age', 'DT', 'npp', 'order_month', 'order_year',\n",
       "       'delivery_month', 'delivery_year', 'item_popularity',\n",
       "       'brand_popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.get_dummies(ord_test)\n",
    "# test.columns\n",
    "ord_test = pd.DataFrame()\n",
    "ord_test['order_month'] = df_test['order_month'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hagen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hagen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hagen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hagen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "### Encode categorical values\n",
    "# 1. get variables that need to be 1-hot-encoded: item_size, item_color, user_title, user_state, order_month, order_year\n",
    "# ... delivery_month, delivery_year, item_popularity, brand_popularity\n",
    "cat_train = df_train[['item_size', 'item_color', 'user_title', 'user_state',\n",
    "                     'delivery_month', 'delivery_year', 'item_popularity', 'brand_popularity']]\n",
    "\n",
    "cat_test = df_train[['item_size', 'item_color', 'user_title', 'user_state',\n",
    "                     'delivery_month', 'delivery_year', 'item_popularity', 'brand_popularity']]\n",
    "\n",
    "ord_train = pd.DataFrame()\n",
    "ord_train['order_month'] = df_train['order_month'].astype('category').copy()\n",
    "ord_train['order_year'] = df_train['order_year'].astype('category').copy()\n",
    "\n",
    "ord_test = pd.DataFrame()\n",
    "ord_test['order_month'] = df_test['order_month'].astype('category').copy()\n",
    "ord_test['order_year'] = df_test['order_year'].astype('category').copy()\n",
    "\n",
    "cat_train['order_month'] = ord_train.order_month\n",
    "cat_train['order_year'] = ord_train.order_year\n",
    "\n",
    "cat_test['order_month'] = ord_test.order_month\n",
    "cat_test['order_year'] = ord_test.order_year\n",
    "\n",
    "cat_train = pd.get_dummies(cat_train)\n",
    "cat_test = pd.get_dummies(cat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_size_36', 'item_size_37', 'item_size_38', 'item_size_39',\n",
       "       'item_size_40', 'item_size_41', 'item_size_42', 'item_size_43',\n",
       "       'item_size_44', 'item_size_46', 'item_size_l', 'item_size_m',\n",
       "       'item_size_other', 'item_size_s', 'item_size_unsized', 'item_size_xl',\n",
       "       'item_size_xxl', 'item_color_anthracite', 'item_color_berry',\n",
       "       'item_color_black', 'item_color_blue', 'item_color_brown',\n",
       "       'item_color_denim', 'item_color_green', 'item_color_grey',\n",
       "       'item_color_ocher', 'item_color_olive', 'item_color_other',\n",
       "       'item_color_petrol', 'item_color_purple', 'item_color_red',\n",
       "       'item_color_white', 'user_title_Company', 'user_title_Family',\n",
       "       'user_title_Mr', 'user_title_Mrs', 'user_title_not reported',\n",
       "       'user_state_Baden-Wuerttemberg', 'user_state_Bavaria',\n",
       "       'user_state_Berlin', 'user_state_Brandenburg', 'user_state_Bremen',\n",
       "       'user_state_Hamburg', 'user_state_Hesse', 'user_state_Lower Saxony',\n",
       "       'user_state_Mecklenburg-Western Pomerania',\n",
       "       'user_state_North Rhine-Westphalia', 'user_state_Rhineland-Palatinate',\n",
       "       'user_state_Saarland', 'user_state_Saxony', 'user_state_Saxony-Anhalt',\n",
       "       'user_state_Schleswig-Holstein', 'user_state_Thuringia',\n",
       "       'delivery_month_1.0', 'delivery_month_2.0', 'delivery_month_3.0',\n",
       "       'delivery_month_4.0', 'delivery_month_5.0', 'delivery_month_6.0',\n",
       "       'delivery_month_7.0', 'delivery_month_8.0', 'delivery_month_9.0',\n",
       "       'delivery_month_10.0', 'delivery_month_11.0', 'delivery_month_12.0',\n",
       "       'delivery_month_other', 'delivery_year_2012.0', 'delivery_year_2013.0',\n",
       "       'delivery_year_other', 'item_popularity_normal',\n",
       "       'item_popularity_popular', 'item_popularity_rare',\n",
       "       'brand_popularity_normal', 'brand_popularity_popular',\n",
       "       'brand_popularity_rare', 'order_month_1', 'order_month_2',\n",
       "       'order_month_3', 'order_month_4', 'order_month_5', 'order_month_6',\n",
       "       'order_month_7', 'order_month_8', 'order_month_9', 'order_month_10',\n",
       "       'order_month_11', 'order_month_12', 'order_year_2012',\n",
       "       'order_year_2013'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_size', 'item_color', 'item_price', 'user_title', 'user_state',\n",
       "       'return', 'LOC', 'age', 'DT', 'npp', 'order_month', 'order_year',\n",
       "       'delivery_month', 'delivery_year', 'item_popularity',\n",
       "       'brand_popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get continouus values\n",
    "cont_train = df_train[['item_price', 'LOC', 'age', 'DT', 'npp']].copy()\n",
    "cont_test = df_test[['item_price', 'LOC', 'age', 'DT', 'npp']].copy()\n",
    "\n",
    "#standardize them\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(cont_train)\n",
    "cont_train = pd.DataFrame(sc.transform(cont_train))\n",
    "cont_test = pd.DataFrame(sc.transform(cont_test))\n",
    "\n",
    "\n",
    "#join them back together\n",
    "X_train = pd.concat([cat_train, cont_train], axis=1)\n",
    "y_train = df_train['return']\n",
    "\n",
    "X_test = pd.concat([cat_test, cont_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 37138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 94)"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=2000.0, random_state=0)\n",
    "lr.fit(X_train.values, y_train.values)\n",
    "y_predict = lr.predict(X_train.values)\n",
    "error = sum(abs(y_train.values - y_predict))\n",
    "print('Error: {}'.format(error))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 94)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "clf.fit(X_train.values, y_train.values)\n",
    "y_predict = clf.predict(X_train.values)\n",
    "error = sum(abs(y_train.values - y_predict))\n",
    "print('Error: {}'.format(error))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98574"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (1426/100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
